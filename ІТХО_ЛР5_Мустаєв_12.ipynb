{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V28","authorship_tag":"ABX9TyOaAcgw+fGmf8hgb+uOt0Jh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nTRfVggKSSQ3","executionInfo":{"status":"ok","timestamp":1727696842127,"user_tz":-180,"elapsed":707,"user":{"displayName":"Тімур Мустаєв","userId":"14811792969024553339"}},"outputId":"2db52525-9c30-421f-f974-4a19cc054973"},"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.10.12\n"]}],"source":["!python --version"]},{"cell_type":"code","source":["def quicksort(arr):\n"," if len(arr) <= 1:\n","  return arr\n"," pivot = arr[len(arr) // 2]\n"," left = [x for x in arr if x < pivot]\n"," middle = [x for x in arr if x == pivot]\n"," right = [x for x in arr if x > pivot]\n"," return quicksort(left) + middle + quicksort(right)\n","\n","print(quicksort([3,6,8,10,1,2,1]))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BU0TWL_OwgJ4","executionInfo":{"status":"ok","timestamp":1727696884204,"user_tz":-180,"elapsed":308,"user":{"displayName":"Тімур Мустаєв","userId":"14811792969024553339"}},"outputId":"ce1a9c91-4bd0-4bef-87cf-f28f1a224730"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1, 1, 2, 3, 6, 8, 10]\n"]}]},{"cell_type":"code","source":["import zipfile\n","\n","with zipfile.ZipFile('dataset.zip', 'r') as zip_ref:\n","  zip_ref.extractall()"],"metadata":{"id":"jGQ1w50t7ya5","executionInfo":{"status":"ok","timestamp":1728676896813,"user_tz":-180,"elapsed":518,"user":{"displayName":"Тімур Мустаєв","userId":"14811792969024553339"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import cv2\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import accuracy_score, precision_score\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import matplotlib.pyplot as plt\n","\n","def create_cnn_model(input_shape, num_classes):\n","    model = Sequential()\n","    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Conv2D(64, (3, 3), activation='relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Conv2D(128, (3, 3), activation='relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Flatten())\n","    model.add(Dense(128, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(Dense(num_classes, activation='softmax'))\n","\n","    return model\n","\n","data_dir = '../content/YogaPoses/'\n","classes = os.listdir(data_dir)\n","\n","images = []\n","labels = []\n","\n","for class_name in classes:\n","    class_path = os.path.join(data_dir, class_name)\n","    for image_name in os.listdir(class_path):\n","            img_path = os.path.join(class_path, image_name)\n","            img = cv2.imread(img_path)\n","            img = cv2.resize(img, (128, 128))\n","            images.append(img)\n","            labels.append(class_name)\n","\n","images = np.array(images)\n","labels = np.array(labels)\n","\n","label_encoder = LabelEncoder()\n","labels_encoded = label_encoder.fit_transform(labels)\n","\n","X_train, X_test, y_train, y_test = train_test_split(images, labels_encoded, test_size=0.2, random_state=42)\n","X_train = X_train.astype('float32') / 255.0\n","X_test = X_test.astype('float32') / 255.0\n","\n","input_shape = (128, 128, 3)\n","num_classes = len(np.unique(labels_encoded))\n","\n","model = create_cnn_model(input_shape, num_classes)\n","\n","model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","history = model.fit(X_train, y_train, epochs=25, batch_size=32)\n","\n","y_pred_prob = model.predict(X_test)\n","\n","y_pred = np.argmax(y_pred_prob, axis=1)\n","\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred, average='weighted')\n","\n","print(f'Ефективність роботи моделі (точність): {accuracy:.2f}')\n","print(f'Precision моделі: {precision:.2f}')\n"],"metadata":{"id":"7LneBgrvQ5wt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728677273827,"user_tz":-180,"elapsed":60422,"user":{"displayName":"Тімур Мустаєв","userId":"14811792969024553339"}},"outputId":"eb633824-f57d-480c-c89e-728bd37e4243"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/25\n","25/25 [==============================] - 3s 93ms/step - loss: 1.5926 - accuracy: 0.2823\n","Epoch 2/25\n","25/25 [==============================] - 2s 92ms/step - loss: 1.1006 - accuracy: 0.5797\n","Epoch 3/25\n","25/25 [==============================] - 2s 91ms/step - loss: 0.7633 - accuracy: 0.7013\n","Epoch 4/25\n","25/25 [==============================] - 2s 93ms/step - loss: 0.5893 - accuracy: 0.7658\n","Epoch 5/25\n","25/25 [==============================] - 2s 92ms/step - loss: 0.4321 - accuracy: 0.8468\n","Epoch 6/25\n","25/25 [==============================] - 2s 92ms/step - loss: 0.3415 - accuracy: 0.8772\n","Epoch 7/25\n","25/25 [==============================] - 2s 92ms/step - loss: 0.2574 - accuracy: 0.9063\n","Epoch 8/25\n","25/25 [==============================] - 2s 92ms/step - loss: 0.1732 - accuracy: 0.9367\n","Epoch 9/25\n","25/25 [==============================] - 2s 92ms/step - loss: 0.1236 - accuracy: 0.9532\n","Epoch 10/25\n","25/25 [==============================] - 2s 92ms/step - loss: 0.1014 - accuracy: 0.9671\n","Epoch 11/25\n","25/25 [==============================] - 2s 93ms/step - loss: 0.0711 - accuracy: 0.9785\n","Epoch 12/25\n","25/25 [==============================] - 2s 91ms/step - loss: 0.0779 - accuracy: 0.9734\n","Epoch 13/25\n","25/25 [==============================] - 2s 92ms/step - loss: 0.0675 - accuracy: 0.9810\n","Epoch 14/25\n","25/25 [==============================] - 2s 92ms/step - loss: 0.0624 - accuracy: 0.9785\n","Epoch 15/25\n","25/25 [==============================] - 2s 94ms/step - loss: 0.0535 - accuracy: 0.9810\n","Epoch 16/25\n","25/25 [==============================] - 2s 93ms/step - loss: 0.0442 - accuracy: 0.9848\n","Epoch 17/25\n","25/25 [==============================] - 2s 91ms/step - loss: 0.0359 - accuracy: 0.9873\n","Epoch 18/25\n","25/25 [==============================] - 2s 92ms/step - loss: 0.0628 - accuracy: 0.9848\n","Epoch 19/25\n","25/25 [==============================] - 2s 92ms/step - loss: 0.0375 - accuracy: 0.9924\n","Epoch 20/25\n","25/25 [==============================] - 2s 92ms/step - loss: 0.0261 - accuracy: 0.9911\n","Epoch 21/25\n","25/25 [==============================] - 2s 94ms/step - loss: 0.0323 - accuracy: 0.9937\n","Epoch 22/25\n","25/25 [==============================] - 2s 94ms/step - loss: 0.0203 - accuracy: 0.9924\n","Epoch 23/25\n","25/25 [==============================] - 2s 94ms/step - loss: 0.0203 - accuracy: 0.9949\n","Epoch 24/25\n","25/25 [==============================] - 2s 91ms/step - loss: 0.0390 - accuracy: 0.9886\n","Epoch 25/25\n","25/25 [==============================] - 2s 92ms/step - loss: 0.0112 - accuracy: 0.9975\n","7/7 [==============================] - 0s 26ms/step\n","Ефективність роботи моделі (точність): 0.92\n","Precision моделі: 0.93\n"]}]}]}